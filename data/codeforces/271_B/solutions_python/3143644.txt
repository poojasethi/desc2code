# encoding: utf-8

def makePrimeTable(limit):
    isPrime = [True] * (limit)
    isPrime[0] = False
    isPrime[1] = False
    for i in range(2, limit):
        if isPrime[i]:
            for j in range(i + i, limit, i):
                isPrime[j] = False
    return isPrime

def makeMinPrimeTable(is_prime):
    min_prime = [None] * len(is_prime)
    p = 2
    for i in range(len(is_prime) - 1, -1, -1):
        if is_prime[i]:
            p = i
        min_prime[i] = p
    return min_prime

if __name__ == '__main__':
    n, m = [int(x) for x in raw_input().rstrip().split()]
    matrix = []
    for i in range(n):
        matrix.append([int(x) for x in raw_input().rstrip().split()])

    limit = 10 ** 6 + 1
    prime_table = makePrimeTable(limit)
    min_prime = makeMinPrimeTable(prime_table)

    toPrime = []
    for row in matrix:
        toPrime.append([min_prime[x] - x for x in row])

    min_row = min([sum(row) for row in toPrime])
    min_col = min([sum(row) for row in map(list, zip(*toPrime))])

    print min(min_row, min_col)