#include <iostream>
#include <bitset>
using namespace std;
 
typedef long long ll;
 
bitset<1700> b[1700];
int a[1700][1700];
 
int main() {
	// your code goes here
	int n, m, i, j;
	ll x, y, ans=0;
	char c;
	cin>>n>>m;
	for(i=1; i<=n; ++i) {
		for(j=1; j<=m; ++j) {
			cin>>c;
			a[i][j]=c-'0';
			a[i][j]^=a[i-1][j]^a[i][j-1]^a[i-1][j-1];
			b[i][j]=a[i][j];
			//cout<<a[i][j]<<" ";
		}
		//cout<<endl;
	}
	for(i=1; i<=n; ++i) {
		for(j=0; j<i; ++j) {
			x=(b[i]^b[j]).count();
			y=m+1-x;
			ans+=x*(x-1LL)/2LL;
			ans+=y*(y-1LL)/2LL;
		}
	}
	cout<<ans<<endl;
	return 0;
} 